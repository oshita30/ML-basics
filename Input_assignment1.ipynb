{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to the colab notebook\n",
    "# https://colab.research.google.com/drive/1ULW_nGPK74Y8t4Sp4PksIrJqhf-2yj-t#scrollTo=v3hw3KYKfQzt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mslHWec23kI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import tree\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OOt7PYHGGWvH"
   },
   "outputs": [],
   "source": [
    "!wget https://www.cmi.ac.in/~madhavan/courses/dmml2021apr/assignment1/bank-data.zip\n",
    "!unzip bank-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YkkqRiRRGd3G"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/HP/OneDrive/Desktop/Python Codes/Python DataSets/bank-additional-full.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yWdZ_dJIieC"
   },
   "outputs": [],
   "source": [
    "categorical_columns= [col for col in data.columns if data[col].dtype==\"O\"]\n",
    "numeric_columns= [col for col in data.columns if data[col].dtype!=\"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQeQ2l1rGjOP"
   },
   "outputs": [],
   "source": [
    "for label in categorical_columns:\n",
    "      plt.figure(figsize=(20,10))\n",
    "      Y = data['y']\n",
    "      total = len(Y)*1.\n",
    "      ax=sns.countplot(x=label, data=data, hue=\"y\")\n",
    "      for p in ax.patches:\n",
    "        ax.annotate('{:.1f}%'.format(100*p.get_height()/total), (p.get_x()+0.1, p.get_height()+5))\n",
    "  \n",
    "      ax.yaxis.set_ticks(np.linspace(0, total, 11))\n",
    "      ax.set_yticklabels(map('{:.1f}%'.format, 100*ax.yaxis.get_majorticklocs()/total))\n",
    "      ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "  \n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcO5ZGCBGjPl"
   },
   "outputs": [],
   "source": [
    "# since the data is imbalanced (88.7% yes, and 11.3% no), and we dont want to lose any potential customers,\n",
    "# thus we focus on attributes that affect the positive response more than negative response\n",
    "\n",
    "# month affects negative responses more than positive responses (positive response is almost same for all months), so it can be dropped\n",
    "# both negative and positive response is same for almost all day_of_week\n",
    "# default seems important but then there is not much variation in default, almost all entries are 'no' and we will replace 'unknown' with 'no' later.\n",
    "# education also does not affect positive responses much, but we can keep it\n",
    "# job seems reasonable to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdIZCTu2GjTz"
   },
   "outputs": [],
   "source": [
    "# conclusion: categorical columns to remove\n",
    "#default\n",
    "#month\n",
    "#day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c28BJXLYMT4D"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.boxplot(data=data,x='y',y='age')\n",
    "# the both labels 'yes' and 'no' have almost the same centre (median), thus age doesnt affect y much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eptL7apIMWkC"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.boxplot(data=data,x='y',y='campaign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGD7HDWFytZU"
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "max(data['campaign']), min(data['campaign']), statistics.variance(data['campaign']), statistics.median(data['campaign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kwiU_Uay9YV"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=data[data['campaign']<6],x='y',y='campaign')\n",
    "# seems like campaign affects y somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYm0vwZs1O8j"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=data[data['pdays']!=999],x='y',y='pdays')\n",
    "# pdays also affects target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWTemsbk1mNF"
   },
   "outputs": [],
   "source": [
    "  plt.figure(figsize=(20,10))\n",
    "  Y = data['y']\n",
    "  total = len(Y)*1.\n",
    "  ax=sns.countplot(x='pdays', data=data[data['pdays']==999], hue=\"y\")\n",
    "  for p in ax.patches:\n",
    "    ax.annotate('{:.1f}%'.format(100*p.get_height()/total), (p.get_x()+0.1, p.get_height()+5))\n",
    "\n",
    "  ax.yaxis.set_ticks(np.linspace(0, total, 11))\n",
    "  ax.set_yticklabels(map('{:.1f}%'.format, 100*ax.yaxis.get_majorticklocs()/total))\n",
    "  ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "  plt.show()\n",
    "\n",
    "# 8.9% of clients who were not contacted before took the term deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hg1r9wTj27NC"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=data[data['previous']<3],x='y',y='previous')\n",
    "# took data=data[data['previous']<3] because outliers were compressing the boxplot making it unreadable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BmKF5XKA3Yqk"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=data,x='y',y='emp.var.rate')\n",
    "# important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwZsR89u3vsx"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=data,x='y',y='emp.var.rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QJ5vboo36en"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=data,x='y',y='cons.price.idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fS41_Pm3_zK"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=data,x='y',y='euribor3m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCkSNzX24IWU"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=data,x='y',y='nr.employed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Fy-gRo1rhD4"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=data[data['duration']<1400],x='y',y='duration')\n",
    "# as written in metadata and visible from the boxplot, duration highly affects the class and is not always obtained for the test data\n",
    "# thus removing it from test as well as train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10RhdXp14P0_"
   },
   "outputs": [],
   "source": [
    "#conclusion: remove \n",
    "#age\n",
    "#default\n",
    "#month\n",
    "#day_of_week\n",
    "#duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lxj5RrEv5D5Y"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(data.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pM1338UqsUzp"
   },
   "outputs": [],
   "source": [
    "# delete duration column altogether\n",
    "data.drop(['duration'], axis=1,inplace=True)\n",
    "# not keeping 'duration' in test data because as given in the txt file, it may or may not be available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJCaZt2PsU66"
   },
   "outputs": [],
   "source": [
    "# cleaning the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGyiIWOFsU-b"
   },
   "outputs": [],
   "source": [
    "# remove features based on the plots above\n",
    "data.drop(['age','default','month','day_of_week'], axis=1,inplace=True)\n",
    "\n",
    "\n",
    "# divide training data into yes and no class labels for further process\n",
    "data_no = data[data['y']=='no']\n",
    "data_yes = data[data['y']=='yes']\n",
    "\n",
    "\n",
    "# 1) delete duplicates with class label = 'no'\n",
    "data_no = data_no.drop_duplicates()\n",
    "\n",
    "# 2) delete missing data rows with class label = 'no'\n",
    "missing_rows = []\n",
    "for i in data_no.index:\n",
    "      if any(data_no.loc[i]=='unknown'):\n",
    "        missing_rows.append(i)   # missing_rows = list of indices of rows with missing data\n",
    "data_no.drop(index=missing_rows,inplace=True)\n",
    "\n",
    "# 3) for rows with missing data and class label = 'yes', replace unknown with mode of column\n",
    "cat_col = [col for col in data_yes.columns if data_yes[col].dtype==\"O\"]\n",
    "for x in cat_col:\n",
    "      data_yes[x] = data_yes[x].replace(['unknown'],data[x].mode()[0])\n",
    "\n",
    "# not deleting duplicate rows with class label = 'yes' to stabilise the data with 'yes' as results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_zMkacvAIh7"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data_no,data_yes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-uBApKXbRAn"
   },
   "outputs": [],
   "source": [
    "# encode categorical variables in data\n",
    "for x in (col for col in data.columns if data[col].dtype==\"O\"):\n",
    "      enc= LabelEncoder()\n",
    "      data[x]= enc.fit_transform(data[x])\n",
    "      print(x,{labels:encoder for labels, encoder in enumerate(enc.classes_)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMMZRxaobN-g"
   },
   "outputs": [],
   "source": [
    "# divide into test and train\n",
    "x= data.iloc[:, :-1]\n",
    "y= data.iloc[:, -1:]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywKiTqDgLPqh"
   },
   "outputs": [],
   "source": [
    "  plt.figure(figsize=(20,10))\n",
    "  Y = y_train\n",
    "  total = len(Y)*1.\n",
    "  ax=sns.countplot(x='y', data=y_train, hue=\"y\")\n",
    "  for p in ax.patches:\n",
    "    ax.annotate('{:.1f}%'.format(100*p.get_height()/total), (p.get_x()+0.1, p.get_height()+5))\n",
    "  \n",
    "  ax.yaxis.set_ticks(np.linspace(0, total, 11))\n",
    "  ax.set_yticklabels(map('{:.1f}%'.format, 100*ax.yaxis.get_majorticklocs()/total))\n",
    "  ax.set_xticklabels(ax.get_xticklabels())\n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FA5gaXkeEZsg"
   },
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZBXiHFwARR_"
   },
   "outputs": [],
   "source": [
    "'''param_grid= {'n_estimators':[500], 'min_samples_split': [5,10,15,20], 'max_depth':[4,5,6,10,15,20]}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 0,scoring='recall')\n",
    "grid.fit(x_train, y_train) \n",
    " \n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFvVeKjbASTS"
   },
   "outputs": [],
   "source": [
    "# {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 500} = output of above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwyQoomOVSl_"
   },
   "outputs": [],
   "source": [
    "'''param_grid= {'n_estimators':[200], 'min_samples_split': [5,10,15,20], 'max_depth':[4,5,6,10,15,20]}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 0,scoring='recall')\n",
    "grid.fit(x_train, y_train) \n",
    " \n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIaerprjXerN"
   },
   "outputs": [],
   "source": [
    "#{'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 200} = output of above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUGH3eh2UEiX"
   },
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "\n",
    "rf= RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=20,bootstrap=True, min_samples_split= 5, min_impurity_split=0.1,\n",
    "                           oob_score=True, random_state=1)\n",
    "model1= rf.fit(x_train, y_train)\n",
    "pred_train= model1.predict(x_train)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print('TRAIN')\n",
    "print(classification_report(y_train,pred_train))\n",
    "print('recall= ',recall_score(y_train,pred_train))\n",
    "print()\n",
    "predictions= model1.predict(x_test)\n",
    "print('TEST')\n",
    "print(classification_report(y_test,predictions))\n",
    "print('recall= ',recall_score(y_test,predictions))\n",
    "print('f1_score= ',f1_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nivEE2ToQFwt"
   },
   "outputs": [],
   "source": [
    "model1.oob_score_  #Sort of validation score\n",
    "#So model generalises well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QwEImIYQF0n"
   },
   "outputs": [],
   "source": [
    "#Feature Importance\n",
    "model1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PK5-7PTGQMPF"
   },
   "outputs": [],
   "source": [
    "feature_names = [x for x in x_train.columns]\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6r3VhnuDQMSB"
   },
   "outputs": [],
   "source": [
    "std = np.std([\n",
    "    tree.feature_importances_ for tree in model1.estimators_], axis=0)\n",
    "\n",
    "\n",
    "forest_importances = pd.Series(model1.feature_importances_, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hfBM_mDQ9Tf"
   },
   "outputs": [],
   "source": [
    "# Data frame of feature importance\n",
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = x.columns,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "\n",
    "feature_importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBPt3spkdJbZ"
   },
   "outputs": [],
   "source": [
    "# Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xzhEOCNdMGx"
   },
   "outputs": [],
   "source": [
    "'''param_grid= { 'min_samples_split': [5,10,15,20], 'max_depth':[2,3,4,5,6,7,8],'min_impurity_split':[0.1,0.2,0.3,0.4],'random_state':[1]}\n",
    "\n",
    "grid = GridSearchCV(tree.DecisionTreeClassifier(), param_grid, refit = True, verbose = 0,scoring='recall')\n",
    "grid.fit(x_train, y_train) \n",
    " \n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-ftjniKdewz"
   },
   "outputs": [],
   "source": [
    "# {'max_depth': 8, 'min_impurity_split': 0.1, 'min_samples_split': 10, 'random_state': 1} = output of above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmyOd8WOdMJs"
   },
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier(max_depth=8,min_samples_split=10,min_impurity_split=0.1, random_state=1)\n",
    "model2 = dtc.fit(x_train, y_train)\n",
    "predictions= model2.predict(x_test)\n",
    "pred_train=model2.predict(x_train)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print('TRAIN')\n",
    "print(classification_report(y_train,pred_train))\n",
    "print('recall= ',recall_score(y_train,pred_train))\n",
    "print()\n",
    "print('TEST')\n",
    "print(classification_report(y_test,predictions))\n",
    "print('recall= ',recall_score(y_test,predictions))\n",
    "print('f1_score= ',f1_score(y_test,predictions))\n",
    "# support is number of occurence of each label in y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgrLoL1Gf5OJ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "dot_data = export_graphviz(dtc, out_file=None, filled=True, rounded=True,\n",
    "                                feature_names=list(x_train.columns),  \n",
    "                                class_names=['no','yes'])\n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph\n",
    "'''\n",
    "\n",
    "#Can be run easily in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8NIzBpudMNT"
   },
   "outputs": [],
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZPv2AmW086H"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(x_train.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMCPK3EI1Km9"
   },
   "outputs": [],
   "source": [
    "# GaussianNB before removing correlated features\n",
    "start = time.time()\n",
    "\n",
    "clf = GaussianNB()\n",
    "model3= clf.fit(x_train,y_train)\n",
    "predictions= model3.predict(x_test)\n",
    "pred_train=model3.predict(x_train)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Runtime of the program is {end - start}\")\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print('TRAIN')\n",
    "print(classification_report(y_train,pred_train))\n",
    "print('recall= ',recall_score(y_train,pred_train))\n",
    "print()\n",
    "print('TEST')\n",
    "print(classification_report(y_test,predictions))\n",
    "print('recall= ',recall_score(y_test,predictions))\n",
    "print('f1_score= ',f1_score(y_test,predictions))\n",
    "# support is number of occurence of each label in y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35Cfq2CC5kN8"
   },
   "outputs": [],
   "source": [
    "# we read somewhere that NB can be applied in mixed data in two ways:\n",
    "# 1) convert all continuous columns to categorical\n",
    "# 2) mixed model containing both GaussianNB() and CategoricalNB()\n",
    "# we try to attempt the 1) solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8yHLxDp5Bdl"
   },
   "outputs": [],
   "source": [
    "# encodin numerical variables in x_train and x_test to apply categorical NB\n",
    "for x in (col for col in x_train.columns if x_train[col].dtype!=\"O\"):\n",
    "      enc= LabelEncoder()\n",
    "      x_train[x]= enc.fit_transform(x_train[x])\n",
    "\n",
    "for x in (col for col in x_test.columns if x_test[col].dtype!=\"O\"):\n",
    "      enc= LabelEncoder()\n",
    "      x_test[x]= enc.fit_transform(x_test[x])\n",
    "\n",
    "# CategoricalNB before removing correlated features\n",
    "start = time.time()\n",
    "\n",
    "clf = CategoricalNB()\n",
    "model3= clf.fit(x_train,y_train)\n",
    "predictions= model3.predict(x_test)\n",
    "pred_train=model3.predict(x_train)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Runtime of the program is {end - start}\")\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print('TRAIN')\n",
    "print(classification_report(y_train,pred_train))\n",
    "print('recall= ',recall_score(y_train,pred_train))\n",
    "print()\n",
    "print('TEST')\n",
    "print(classification_report(y_test,predictions))\n",
    "print('recall= ',recall_score(y_test,predictions))\n",
    "print('f1_score= ',f1_score(y_test,predictions))\n",
    "# support is number of occurence of each label in y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ss8EVAm029-a"
   },
   "outputs": [],
   "source": [
    "x_train.drop(data[['cons.price.idx', 'emp.var.rate', 'nr.employed']], axis=1, inplace=True)\n",
    "x_test.drop(data[['cons.price.idx', 'emp.var.rate', 'nr.employed']], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3hw3KYKfQzt"
   },
   "outputs": [],
   "source": [
    "# GaussianNB after removing correlated features\n",
    "start = time.time()\n",
    "\n",
    "clf = GaussianNB()\n",
    "model3= clf.fit(x_train,y_train)\n",
    "predictions= model3.predict(x_test)\n",
    "pred_train=model3.predict(x_train)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")\n",
    "print()\n",
    "print('TRAIN')\n",
    "print(classification_report(y_train,pred_train))\n",
    "print('recall= ',recall_score(y_train,pred_train))\n",
    "print()\n",
    "print('TEST')\n",
    "print(classification_report(y_test,predictions))\n",
    "print('recall= ',recall_score(y_test,predictions))\n",
    "print('f1_score= ',f1_score(y_test,predictions))\n",
    "# support is number of occurence of each label in y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUySQxdlvG3y"
   },
   "outputs": [],
   "source": [
    "# encodin numerical variables in x_train and x_test to apply categorical NB\n",
    "for x in (col for col in x_train.columns if x_train[col].dtype!=\"O\"):\n",
    "      enc= LabelEncoder()\n",
    "      x_train[x]= enc.fit_transform(x_train[x])\n",
    "\n",
    "for x in (col for col in x_test.columns if x_test[col].dtype!=\"O\"):\n",
    "      enc= LabelEncoder()\n",
    "      x_test[x]= enc.fit_transform(x_test[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afrh0M9ks_I7"
   },
   "outputs": [],
   "source": [
    "# CategoricalNB after removing correlated features\n",
    "start = time.time()\n",
    "\n",
    "clf = CategoricalNB()\n",
    "model3= clf.fit(x_train,y_train)\n",
    "predictions= model3.predict(x_test)\n",
    "pred_train=model3.predict(x_train)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Runtime of the program is {end - start}\")\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print('TRAIN')\n",
    "print(classification_report(y_train,pred_train))\n",
    "print('recall= ',recall_score(y_train,pred_train))\n",
    "print()\n",
    "print('TEST')\n",
    "print(classification_report(y_test,predictions))\n",
    "print('recall= ',recall_score(y_test,predictions))\n",
    "print('f1_score= ',f1_score(y_test,predictions))\n",
    "# support is number of occurence of each label in y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "prasun_oshita assignment1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
